{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q langchain langchain-google-genai faiss-cpu pypdf langchain_community"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NOfIyPwISnnm",
        "outputId": "8f10596b-fa28-4a36-9b68-c65339021dfb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Xc6xj7dT9qd",
        "outputId": "8607d317-b397-4be1-9145-8039e280825a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement pil (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for pil\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.image import imread\n",
        "from IPython.display import display,Markdown"
      ],
      "metadata": {
        "id": "EJSWN3j6TMOs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "api = userdata.get(\"GOOGLE_API_KEY\")\n",
        "os.environ[\"GOOGLE_API_KEY\"]=api"
      ],
      "metadata": {
        "id": "zNEBYI4JUmP6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "\n",
        "from langchain_core.messages import HumanMessage,SystemMessage,AIMessage\n",
        "from langchain_core.output_parsers import StrOutputParser,PydanticOutputParser\n",
        "from langchain.prompts import ChatPromptTemplate"
      ],
      "metadata": {
        "id": "vNBHWGTPVCsE"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.vectorstores import FAISS"
      ],
      "metadata": {
        "id": "-HMpKOwBVCvA"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "def get_llm(model_name):\n",
        "    if model_name == \"gemini-2.0-flash\":\n",
        "        llm = ChatGoogleGenerativeAI(model=\"models/gemini-2.0-flash\")\n",
        "    else:\n",
        "        llm = ChatGoogleGenerativeAI(model=\"models/gemini-pro-vision\")\n",
        "    return llm\n",
        "\n",
        "model = get_llm(\"gemini-2.0-flash\")\n",
        "response = model.invoke(\"5 facts about Pakistan\")\n",
        "print(response.content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ee8sPmslVCxt",
        "outputId": "b171d863-5f5b-44d4-8723-be40537b648e"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Okay, here are 5 interesting facts about Pakistan:\n",
            "\n",
            "1.  **World's Highest Paved International Road:** The Karakoram Highway, also known as the \"Friendship Highway,\" connects Pakistan and China and is the highest paved international road in the world. It's an engineering marvel and offers stunning mountain scenery.\n",
            "\n",
            "2.  **Home to K2:** Pakistan is home to K2, the second-highest mountain in the world after Mount Everest. It's known as the \"Savage Mountain\" due to its treacherous climbing conditions.\n",
            "\n",
            "3.  **One of the Largest Irrigation Systems:** Pakistan has one of the largest contiguous irrigation systems in the world, fed by the Indus River and its tributaries. This system is crucial for the country's agriculture.\n",
            "\n",
            "4.  **Youngest Nobel Prize Laureate:** Malala Yousafzai, a Pakistani activist for female education, became the youngest Nobel Prize laureate when she was awarded the Nobel Peace Prize in 2014 at the age of 17.\n",
            "\n",
            "5.  **Edible Salt Mines:** The Khewra Salt Mine is the second largest in the world. It is a major tourist attraction, drawing visitors due to its unique structures carved from salt, including a mosque and a replica of the Minar-e-Pakistan. The salt is edible and a major export.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for checking text model\n",
        "model([\n",
        "    HumanMessage(content=\"answer with simple yes or no. is apple red?\")\n",
        "]).content\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "7BzEfsMBVC69",
        "outputId": "84a87003-afb0-4bf9-b9ad-7da6636d551f"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Yes'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for checking image model\n",
        "def get_image(url,filename,extension):\n",
        "  content = requests.get(url).content\n",
        "  with open(f\"/content/{filename}.{extension}\",\"wb\") as f:\n",
        "    f.write(content)\n",
        "  image = Image.open(f\"/content/{filename}.{extension}\")\n",
        "  image.show()\n",
        "  return image"
      ],
      "metadata": {
        "id": "zlBpl0f0hGkc"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image = get_image(\"https://earthshotprize.org/wp-content/uploads/2023/05/bee-on-flower.jpg\",\n",
        "                  \"shoe_image\",\"png\")"
      ],
      "metadata": {
        "id": "YYS42GOghDx9"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gemini (and other multimodal models) expects an image URL or base64 image in a very specific format.\n",
        "# This function ensures that your local or in-memory PIL image is converted into exactly what the model requires.\n",
        "import base64\n",
        "from io import BytesIO\n",
        "def pil_image_to_base64_url(pil_image, format=\"JPEG\"):\n",
        "    buffered = BytesIO()     # It creates an in-memory binary stream — like a fake file stored in RAM. it store image in memory\n",
        "    pil_image.save(buffered, format=format)  # This saves the PIL image into the BytesIO buffer as if it's writing to a file\n",
        "    # Base64 is a way of encoding binary data (like images) into a text format\n",
        "    # buffered.getvalue() gets the raw binary image data from the buffer.\n",
        "    # .decode() turns the base64 bytes into a regular UTF-8 string.\n",
        "    img_base64 = base64.b64encode(buffered.getvalue()).decode()\n",
        "    return f\"data:image/{format.lower()};base64,{img_base64}\"\n",
        "\n",
        "image = pil_image_to_base64_url(image,\"png\")\n"
      ],
      "metadata": {
        "id": "lplwb_r0-V8E"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "message = HumanMessage(\n",
        "    content=[\n",
        "        {\n",
        "            \"type\":\"image_url\",\n",
        "            \"image_url\":image\n",
        "        }\n",
        "    ]\n",
        ")\n",
        "model=get_llm(\"models/gemini-pro-vision\")\n",
        "model.invoke([message]).content     # it require a list of message"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "id": "uNmt5c_X8zke",
        "outputId": "3eb18f25-f475-4f97-cca9-2ca44ad114ee"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"The image is a close-up, macro photograph of a bumblebee (likely a common eastern bumblebee or a similar species) on a bright yellow flower.  The focus is sharply on the bee, showcasing its fuzzy body, black and yellow stripes, and its delicate legs and antennae. The bee appears to be gathering pollen or nectar.\\n\\nThe flower, likely a type of daisy or sunflower, is a vibrant, rich yellow. The central disc florets where the bee is perched are in sharp focus, creating a textured, almost velvety appearance.  The petals of the flower, extending outwards, are slightly blurred, creating a soft, bokeh effect.\\n\\nThe background is also blurred, with a gradient of yellow and darker tones, suggesting other flowers or foliage out of focus. This blurring helps to isolate the bee and the flower it's on, drawing the viewer's attention to the main subject.  The overall impression is one of warmth, brightness, and nature's intricate beauty.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/a-introduction-bees-july2013.pdf\"\n",
        "def doc_loader(path_to_pdf):\n",
        "  loader = PyPDFLoader(path_to_pdf)\n",
        "  return loader.load()\n",
        "\n",
        "doc = doc_loader(path)"
      ],
      "metadata": {
        "id": "9r_aw1Hv7HeA"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def text_splitter(doc):\n",
        "  splitter = RecursiveCharacterTextSplitter(chunk_size=400,chunk_overlap=65)\n",
        "  return splitter.split_documents(doc)\n",
        "chunks = text_splitter(doc=doc)"
      ],
      "metadata": {
        "id": "lXHCgTYx8d0n"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_model = GoogleGenerativeAIEmbeddings(model = \"models/embedding-001\")\n",
        "vector_store = FAISS.from_documents(documents=chunks,\n",
        "                                    embedding=embedding_model)"
      ],
      "metadata": {
        "id": "DUpzZrhSQ6p4"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = vector_store.as_retriever(search_type=\"similarity\",search_kwargs={\"k\":3})"
      ],
      "metadata": {
        "id": "6i5DWX8oS3Qi"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "context = retriever.invoke(\"type of bee\")\n",
        "\n",
        "def context_format(context):\n",
        "  return \"\\n\\n\".join(doc.page_content for doc in context)\n"
      ],
      "metadata": {
        "id": "4VicWWrITTLX"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_llm = get_llm(\"gemini-2.0-flash\")\n",
        "image_model = get_llm(\"text_model\")"
      ],
      "metadata": {
        "id": "Ok7GUTIUV2el"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = ChatPromptTemplate.from_template(\n",
        "    template = \"\"\"{context}\n",
        "          {question}\n",
        "  Provide brief information and type of bee if possible from the context.\n",
        "    \"\"\"\n",
        ")"
      ],
      "metadata": {
        "id": "VAWHrLo9VDLh"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.runnables import RunnableParallel,RunnablePassthrough,RunnableLambda\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "parser = StrOutputParser()\n",
        "\n",
        "parallel_chain = RunnableParallel({\n",
        "    \"context\": retriever | RunnableLambda(context_format),\n",
        "    \"question\":RunnablePassthrough()\n",
        "})\n",
        "\n",
        "final_chain_text = parallel_chain | prompt | text_llm | parser\n"
      ],
      "metadata": {
        "id": "-JNylfVoVvpA"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = final_chain.invoke(\"type of bees\")\n",
        "display(Markdown(result))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 623
        },
        "id": "Nqj8ZjGBVvrx",
        "outputId": "5714bd3d-2781-4ca4-d73a-e640157c8e16"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Here's a breakdown of the bee species mentioned in the context, along with information provided:\n\n*   **A. mellifera (European Honey Bee):**\n    *   Medium-sized workers.\n    *   Cavity-nesting (builds nests in hollow spaces).\n    *   Found almost worldwide.\n    *   24 races exist.\n    *   Some subspecies are important for managed beekeeping.\n    *   *A.m. scutellata* (African bee) is a subspecies known for aggressive behavior.\n\n*   **A. cerana (Asiatic Honey Bee):**\n    *   Medium-sized workers.\n\n*   **A. nigrocincta (Celebes Honey Bee):**\n    *   Medium-sized workers.\n\n*   **A. koschevnikovi (Koschevnikov's Honey Bee):**\n    *   Medium-sized workers.\n\n*   **A. nuluensis (Mount Nulu Honey Bee):**\n    *   Medium-sized workers.\n\n*   **A. florea (Red Dwarf Honey Bee):**\n    *   Dwarf bee species.\n    *   Builds single-comb open nests.\n\n*   **A. andreniformis (Black Dwarf Honey Bee):**\n    *   Dwarf bee species.\n    *   Builds single-comb open nests.\n\n*   **A. dorsata (Giant Honey Bee):**\n    *   Giant bee species.\n    *   Builds single-comb open nests.\n\n*   **A. laboriosa (Himalayan Honey Bee):**\n    *   Giant bee species.\n    *   Builds single-comb open nests."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "full_chain = RunnablePassthrough() | image_model | parser | final_chain_text"
      ],
      "metadata": {
        "id": "WzyRBg-cVvuX"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import HumanMessage\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "message = HumanMessage(content=[\n",
        "    {\n",
        "        \"type\": \"text\",\n",
        "        \"text\": \"Provide information about the image from the context only\"\n",
        "    },\n",
        "    {\n",
        "        \"type\": \"image_url\",\n",
        "        \"image_url\": image  # make sure this is a valid base64 or hosted URL\n",
        "    }\n",
        "])\n",
        "\n",
        "final_result = full_chain.invoke([message])\n",
        "display(Markdown(final_result))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "id": "B0fKQKAtTckP",
        "outputId": "5815226d-97d9-49bb-edc0-a81e5ab2ce5e"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Based on the text and the image:\n\n*   **Type of Bee:** Bumblebee (as described in the image caption)\n*   **Information:**\n    *   Honey bees are important pollinators.\n    *   Bee colonies are complex societies where individual bees rely on each other to survive."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "q4PMLserZJCM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}