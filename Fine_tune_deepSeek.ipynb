{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "xEPK2Kqp3OkY"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DkvGkW61UGzH",
    "outputId": "d0a255e4-cb7a-4e23-94df-a00a4a61f5f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.4/491.4 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m109.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m91.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m49.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! pip install -q wandb peft datasets bitsandbytes accelerate\n",
    "#You likely installed accelerate as a dependency of transformers or peft. It's used under the hood, especially when you:\n",
    "# Use Trainer\n",
    "# Enable fp16=True in TrainingArguments\n",
    "# Train on multiple GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "id": "9W0KVjcL6_Nf"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import wandb\n",
    "import pandas as pd\n",
    "from peft import LoraConfig,get_peft_model,TaskType,prepare_model_for_kbit_training\n",
    "from datasets import load_dataset,Dataset\n",
    "from transformers import Trainer,TrainingArguments,BitsAndBytesConfig,AutoTokenizer,AutoTokenizer, AutoModelForSeq2SeqLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "OUuCl9L_7H7q",
    "outputId": "c647e127-6cc9-4449-aa56-7c59cde6e1a9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to 'default'."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">firm-resonance-1</strong> at: <a href='https://wandb.ai/haseebmanzoor1511-comsats-university-islamabad/BART%20Fine-Tuning/runs/sq8i64u3?apiKey=e8876843a681e7aa6fd3c5a1c47618a7d950dfa1' target=\"_blank\">https://wandb.ai/haseebmanzoor1511-comsats-university-islamabad/BART%20Fine-Tuning/runs/sq8i64u3?apiKey=e8876843a681e7aa6fd3c5a1c47618a7d950dfa1</a><br> View project at: <a href='https://wandb.ai/haseebmanzoor1511-comsats-university-islamabad/BART%20Fine-Tuning?apiKey=e8876843a681e7aa6fd3c5a1c47618a7d950dfa1' target=\"_blank\">https://wandb.ai/haseebmanzoor1511-comsats-university-islamabad/BART%20Fine-Tuning?apiKey=e8876843a681e7aa6fd3c5a1c47618a7d950dfa1</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250429_115849-sq8i64u3/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20250429_121502-onvdf3h0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/haseebmanzoor1511-comsats-university-islamabad/BART%20Fine-Tuning/runs/onvdf3h0?apiKey=e8876843a681e7aa6fd3c5a1c47618a7d950dfa1' target=\"_blank\">trim-brook-2</a></strong> to <a href='https://wandb.ai/haseebmanzoor1511-comsats-university-islamabad/BART%20Fine-Tuning?apiKey=e8876843a681e7aa6fd3c5a1c47618a7d950dfa1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/haseebmanzoor1511-comsats-university-islamabad/BART%20Fine-Tuning?apiKey=e8876843a681e7aa6fd3c5a1c47618a7d950dfa1' target=\"_blank\">https://wandb.ai/haseebmanzoor1511-comsats-university-islamabad/BART%20Fine-Tuning?apiKey=e8876843a681e7aa6fd3c5a1c47618a7d950dfa1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/haseebmanzoor1511-comsats-university-islamabad/BART%20Fine-Tuning/runs/onvdf3h0?apiKey=e8876843a681e7aa6fd3c5a1c47618a7d950dfa1' target=\"_blank\">https://wandb.ai/haseebmanzoor1511-comsats-university-islamabad/BART%20Fine-Tuning/runs/onvdf3h0?apiKey=e8876843a681e7aa6fd3c5a1c47618a7d950dfa1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Do NOT share these links with anyone. They can be used to claim your runs."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import wandb\n",
    "\n",
    "# Get the WandB API key from Colab's secret storage\n",
    "api_key = os.environ.get('WB_API')\n",
    "\n",
    "# Log into WandB using the API key\n",
    "wandb.login(key=api_key)\n",
    "\n",
    "# Initialize the WandB run\n",
    "run = wandb.init(\n",
    "    project=\"BART Fine-Tuning\",\n",
    "    job_type=\"training\",\n",
    "    anonymous=\"allow\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "id": "p4xrIkQc8RPB"
   },
   "outputs": [],
   "source": [
    "# 4bit Quantization\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",  #non uniform quantization\n",
    "    bnb_4bit_compute_dtype=\"float16\"\n",
    ")\n",
    "\n",
    "# 8-Bit Quantization\n",
    "# bnb_config = BitsAndBytesConfig(\n",
    "#     load_in_8bit=True,             # Enable 8-bit quantization\n",
    "#     llm_int8_threshold=6.0,        # Threshold for outlier detection (default = 6.0)\n",
    "#     llm_int8_skip_modules=None,    # Modules to skip from quantization (optional)\n",
    "#     llm_int8_enable_fp32_cpu_offload=True  # Offload non-quantized weights to CPU\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 168,
     "referenced_widgets": [
      "b1a914dd250546f3a630c326bbb34d3b",
      "a20ee935139942aaa9e49affaa56fce7",
      "fde6aec533ff43d8a990291085643483",
      "27b04bf3cc7146db9f3ce24a78e1faf2",
      "83b4b87ba64740b2be66229cb4c10757",
      "55b31a5ad4ea4c138b57eb938af6fea3",
      "f47288177bd442ba8d5c161c5076845c",
      "97b08c2cf6874735be388b38851b4e8d",
      "d77f2cab54934297a10854111f495318",
      "c7096b363f4447889f3a0387d6ed2018",
      "113554b82ccc41f5bab7fe68aa1eeef7",
      "87dfd132e247411ab3664f6ad2607d86",
      "8c7a451e68f74913be2060d6b509df1c",
      "47c5894f099745ebb608405c1d8e081c",
      "26016e32455644fa925c77017286f542",
      "6621a04772a5446cbd39139e89a988ab",
      "c9d90cd2e9304ea984a3964665ef3537",
      "90dc790a6732493f9ffcb288e39a26e5",
      "1101adce381f40a690be0920e70a98bd",
      "aba218f436d544828d7974adc0392eeb",
      "0f6827ef08374f98b384fe3dade9a7cd",
      "2a287eee8f3b4ccb8e5a8f6a5476757a",
      "d571ed80f1d0491dad8a7fa2495a6073",
      "7a51b0328a58404db814c5487d699b84",
      "39550bbc8974482ea168a23d7020c4e7",
      "894519792c8d4efdaffd9774e7a99e1a",
      "d27d92fd031f41159d709f8dffab7bd0",
      "37157fef316c4e2f9ebe9ba7991727ec",
      "3c312a21e5ed4add9d745f08391d6c98",
      "c0ea25acdcbb428ba86e16f733b1cede",
      "246fc4c71f884b1a8e4cd1c55f16c1f0",
      "ab4a07b9c30746afa80f84eb8f09e65e",
      "deeec262944a4fc588095daaefcbda6b"
     ]
    },
    "id": "6FBmWzox6MmZ",
    "outputId": "1d526af2-abd1-47b4-f4de-d6404841779a"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1a914dd250546f3a630c326bbb34d3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87dfd132e247411ab3664f6ad2607d86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/892M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d571ed80f1d0491dad8a7fa2495a6073",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "model_name = \"google-t5/t5-base\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name,\n",
    "                                             quantization_config=bnb_config,\n",
    "                                             #load_in_4bit=True,  #another methood for applying  Quantization\n",
    "                                            ).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "id": "go3j-L2g87tJ"
   },
   "outputs": [],
   "source": [
    "#prepare model for kbit training\n",
    "model = prepare_model_for_kbit_training(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "id": "j1Lvz-tI9mlo"
   },
   "outputs": [],
   "source": [
    "lora_config = LoraConfig(\n",
    "    r=8,  # Rank of the low-rank matrices (controls adapter capacity; higher = more expressive)\n",
    "    lora_alpha=32,  # Scaling factor for the LoRA weights (controls how much influence adapters have)\n",
    "\n",
    "    # q_proj → Query projection (part of self-attention)\n",
    "    # k_proj → Key projection\n",
    "    # v_proj → Value projection\n",
    "    # o_proj → Output projection (after self-attention)\n",
    "    # gate_proj, up_proj, down_proj → Layers in the Feed-Forward Network (FFN) part\n",
    "    # For small datasets or fast prototyping, just using [\"q_proj\", \"v_proj\"] is often enough.\n",
    "    # For serious fine-tuning, using all of modules gives the model much more flexibility to adapt\n",
    "    target_modules=[\"q\", \"k\", \"v\", \"o\"],  # T5 uses these names inside its attention blocks   # Inject LoRA into Query and Value ... projection layers of attention\n",
    "    lora_dropout=0.05,    # Dropout applied to LoRA layers during training (regularization)\n",
    "    bias=\"none\",   # # No bias term is trained or modified (keeps adapters lightweight)\n",
    "    task_type = TaskType.SEQ_2_SEQ_LM ## Specifies the task type (e.g., autoregressive language modeling)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Iv29e7yh_ko6",
    "outputId": "49dbc6fc-8bbf-418a-bfc3-d5043dee15ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 1,769,472 || all params: 224,673,024 || trainable%: 0.7876\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = get_peft_model(model,lora_config)   # Adds LoRA adapters into the specified layers of the model\n",
    "print(model.print_trainable_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "id": "OAPzKgLv_qei"
   },
   "outputs": [],
   "source": [
    "# loading dataset\n",
    "\n",
    "dataset = load_dataset(\"json\",data_files=\"/content/kashmir_niche_dataset.json\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "id": "-Wrp3aucb_IM"
   },
   "outputs": [],
   "source": [
    "dataset = dataset[\"train\"].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "uEHVYKKwPWIA",
    "outputId": "8a93624d-ed62-4341-8def-c24097b86974"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"dataset\",\n  \"rows\": 107,\n  \"fields\": [\n    {\n      \"column\": \"prompt\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"What is a niche topic about Kashmir, Pakistan?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"response\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 107,\n        \"samples\": [\n          \"Craftsmanship and generational skills\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "dataset"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-9a6a42cb-e955-40cc-b069-94820c7d371f\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is a niche topic about Kashmir, Pakistan?</td>\n",
       "      <td>Natural beauty of Neelum Valley</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is a niche topic about Kashmir, Pakistan?</td>\n",
       "      <td>Cultural traditions of Kashmiri people</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is a niche topic about Kashmir, Pakistan?</td>\n",
       "      <td>Kashmiri embroidery and handicrafts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is a niche topic about Kashmir, Pakistan?</td>\n",
       "      <td>Role of Azad Kashmir in Pakistan's tourism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is a niche topic about Kashmir, Pakistan?</td>\n",
       "      <td>Historical significance of Muzaffarabad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9a6a42cb-e955-40cc-b069-94820c7d371f')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-9a6a42cb-e955-40cc-b069-94820c7d371f button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-9a6a42cb-e955-40cc-b069-94820c7d371f');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-4e611a38-b08f-41f6-9b6b-00ed22fb3cb9\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4e611a38-b08f-41f6-9b6b-00ed22fb3cb9')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-4e611a38-b08f-41f6-9b6b-00ed22fb3cb9 button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                                           prompt  \\\n",
       "0  What is a niche topic about Kashmir, Pakistan?   \n",
       "1  What is a niche topic about Kashmir, Pakistan?   \n",
       "2  What is a niche topic about Kashmir, Pakistan?   \n",
       "3  What is a niche topic about Kashmir, Pakistan?   \n",
       "4  What is a niche topic about Kashmir, Pakistan?   \n",
       "\n",
       "                                     response  \n",
       "0             Natural beauty of Neelum Valley  \n",
       "1      Cultural traditions of Kashmiri people  \n",
       "2         Kashmiri embroidery and handicrafts  \n",
       "3  Role of Azad Kashmir in Pakistan's tourism  \n",
       "4     Historical significance of Muzaffarabad  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W1gbI4XOOYHX",
    "outputId": "f93b2cee-a9b0-4a5c-d0f9-2f47b1de2031"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(107, 2)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "QdTNTNzuPwgD"
   },
   "outputs": [],
   "source": [
    "prompt_max_length = max(len(tokenizer.encode(word)) for word in dataset[\"prompt\"])\n",
    "response_max_length = max(len(tokenizer.encode(word)) for word in dataset[\"response\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "c5c3c3734b384bf1b25d9ec06b6a4f1d",
      "273cc72ea3b84fe2a877a0b7bb1b7663",
      "aca726d10aca4126b4dbf33a0922c8de",
      "691ec2b0fca546ed89c7921c4b3939a6",
      "92390106567e4992a038406a4202d339",
      "90d88ae0033244ba9d473ec90b593266",
      "fa954c9958874db6a62b6a26ad00481d",
      "a2e43b1f89394276ab28c4ca868e6871",
      "04d6596b68d2445da21f63f16b786f69",
      "4611ed1ccff642b489f6c63a31a1b7cd",
      "3396f82379e14ee99062a93ceb6c82ca"
     ]
    },
    "id": "hVT6gJ9rN-qc",
    "outputId": "2dd51000-6a8a-46fe-d6f6-2a2f897b69ed"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5c3c3734b384bf1b25d9ec06b6a4f1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/107 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenization(example):\n",
    "  input = tokenizer(example[\"prompt\"],\n",
    "                    truncation=True,\n",
    "                    padding=\"max_length\",\n",
    "                    max_length=512)\n",
    "  output = tokenizer(example[\"response\"],\n",
    "                     truncation=True,\n",
    "                     padding=\"max_length\",\n",
    "                     max_length=512)\n",
    "  input[\"labels\"]=output[\"input_ids\"]\n",
    "  return input\n",
    "\n",
    "dataset = Dataset.from_pandas(dataset)\n",
    "dataset = dataset.map(tokenization,batched=True)\n",
    "\n",
    "dataset.set_format(type=\"pt\",columns=[\"input_ids\",\"attention_mask\",\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "id": "pL4zA8NxN-tu"
   },
   "outputs": [],
   "source": [
    "split = dataset.train_test_split(test_size=0.2)\n",
    "train_dataset = split[\"train\"]\n",
    "val_dataset = split[\"test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TLTue85ohf0C"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307
    },
    "id": "v6OkYJhwN-w4",
    "outputId": "64ce94f2-bb80-4bf2-b1a9-008f08450c74"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForSeq2SeqLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [20/20 02:02, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>28.346193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>27.504494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>26.911821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>26.664558</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=20, training_loss=22.854965209960938, metrics={'train_runtime': 128.839, 'train_samples_per_second': 2.639, 'train_steps_per_second': 0.155, 'total_flos': 208893860904960.0, 'train_loss': 22.854965209960938, 'epoch': 4.0})"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    train_dataset = train_dataset,\n",
    "    eval_dataset = val_dataset,\n",
    "    args = TrainingArguments(\n",
    "    output_dir =\"content/fin-tuned/checkpints/\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=2,\n",
    "    logging_dir=\"content/fin-tuned/logs/\",\n",
    "    logging_steps=400,\n",
    "    per_device_train_batch_size= 6,\n",
    "    per_device_eval_batch_size = 6,\n",
    "    num_train_epochs=4,\n",
    "    eval_strategy=\"epoch\",\n",
    "    bf16=False,\n",
    "    fp16=False,\n",
    "    gradient_accumulation_steps=3,\n",
    "    report_to=\"wandb\",\n",
    "    load_best_model_at_end=True,\n",
    "    optim = \"paged_adamw_8bit\",   #Essential: memory-efficient optimizer used in QLoRA.\n",
    "    learning_rate=5e-5    #Controls how much the model's weights are updated.\n",
    "    )\n",
    "    )\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aLPuFnN1VJ7t"
   },
   "outputs": [],
   "source": [
    "model = model.save_pretrained('content/fin-tuned/model/')\n",
    "tokenizer=  tokenizer.save_pretrained(\"content/fin-tuned/tokenizer/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L3_GUDZHVYf9"
   },
   "outputs": [],
   "source": [
    "model = 'content/fin-tuned/model/'\n",
    "tokenizer = \"content/fin-tuned/tokenizer/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DfINYk0pVYkW"
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "def inference(text):\n",
    "  pipe = pipeline(\"text-generation\",model=model,tokenizer=tokenizer)\n",
    "  response = pipe(text,num_retun_sequences=1)\n",
    "  return response[0][\"generated_text\"]"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
